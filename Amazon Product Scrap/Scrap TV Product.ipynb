{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ddac5a6",
   "metadata": {},
   "source": [
    "# Web Scrapping Amazon Product [TV]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d27219",
   "metadata": {},
   "source": [
    "## Requests Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d042489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\akash\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "\n",
    "#The requests library is used for making HTTP requests to a specific URL and returns the response. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a15871",
   "metadata": {},
   "source": [
    "*`Python requests module has several built-in methods to make HTTP requests to specified URI using GET, POST, PUT, PATCH, or HEAD requests`*\n",
    "\n",
    "**1. Informational responses (100 – 199)**\n",
    "\n",
    "**2. Successful responses (200 – 299)**\n",
    "\n",
    "**3. Redirection messages (300 – 399)**\n",
    "\n",
    "**4. Client error responses (400 – 499)**\n",
    "\n",
    "**5. Server error responses (500 – 599)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe64871b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [503]>\n",
      "b'<html>\\n<head>\\n<title>503 - Service Unavailable Error</title>\\n</head>\\n<body bgcolor=\"#FFFFFF\" text=\"#000000\">\\n\\n<!--\\n        To discuss automated access to Amazon data please contact api-services-support@amazon.com.\\n        For information about migrating to our APIs refer to our Marketplace APIs at https://developer.amazonservices.in/ref=rm_5_sv, or our Product Advertising API at https://affiliate-program.amazon.in/gp/advertising/api/detail/main.html/ref=rm_5_ac for advertising use cases.\\n-->\\n\\n<center>\\n<a href=\"https://www.amazon.in/ref=cs_503_logo/\">\\n<img src=\"https://images-eu.ssl-images-amazon.com/images/G/31/x-locale/communities/people/logo.gif\" width=200 height=45 alt=\"Amazon.in\" border=0></a>\\n<p align=center>\\n<font face=\"Verdana,Arial,Helvetica\">\\n<font size=\"+2\" color=\"#CC6600\"><b>Oops!</b></font><br>\\n<b>It\\'s rush hour and traffic is piling up on that page. Please try again in a short while.<br>If you were trying to place an order, it will not have been processed at this time.</b><p>\\n\\n<img src=\"https://images-eu.ssl-images-amazon.com/images/G/02/x-locale/common/orange-arrow.gif\" width=10 height=9 border=0 alt=\"*\">\\n<b><a href=\"https://www.amazon.in/ref=cs_503_link/\">Go to the Amazon.in home page to continue shopping</a></b>\\n</font>\\n\\n</center>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Making a GET request\n",
    "r = requests.get('https://www.amazon.in/s?k=TV&rh=n%3A1389396031&ref=nb_sb_noss/')\n",
    "\n",
    "# check status code for response received\n",
    "# success code - 200\n",
    "print(r)\n",
    "\n",
    "# print content of request\n",
    "print(r.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73fb7de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request successful\n",
      "Content retrieved successfully\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "# Function to handle retries\n",
    "def get_amazon_page(url, retries=3):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Connection': 'keep-alive',\n",
    "    }\n",
    "    \n",
    "    for i in range(retries):\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            print(\"Request successful\")\n",
    "            return response.content\n",
    "        elif response.status_code == 503:\n",
    "            print(f\"503 Service Unavailable. Retrying ({i+1}/{retries})...\")\n",
    "            sleep(randint(1, 5))  # Wait a few seconds before retrying\n",
    "        else:\n",
    "            print(f\"Unexpected status code: {response.status_code}\")\n",
    "            break\n",
    "    \n",
    "    return None\n",
    "\n",
    "# URL for the GET request\n",
    "url = 'https://www.amazon.in/s?k=TV&rh=n%3A1389396031&ref=nb_sb_noss/'\n",
    "\n",
    "# Get the content\n",
    "content = get_amazon_page(url)\n",
    "\n",
    "# Check if content was retrieved\n",
    "if content:\n",
    "    print(\"Content retrieved successfully\")\n",
    "else:\n",
    "    print(\"Failed to retrieve content after retries\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ece7ed",
   "metadata": {},
   "source": [
    "## BeautifulSoup Library\n",
    "\n",
    "1. **Importing Libraries:** The code imports the requests library for making HTTP requests and the BeautifulSoup class from the bs4 library for parsing HTML.\n",
    "1. **Making a GET Request:** It sends a GET request to ‘https://www.geeksforgeeks.org/python-programming-language/’ and stores the response in the variable r.\n",
    "1. **Checking Status Code:** It prints the status code of the response, typically 200 for success.\n",
    "1. **Parsing the HTML:** The HTML content of the response is parsed using BeautifulSoup and stored in the variable soup.\n",
    "1. **Printing the Prettified HTML:** It prints the prettified version of the parsed HTML content for readability and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37b9f2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\akash\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a489f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL to scrape\n",
    "url = \"https://www.amazon.in/s?k=TV&rh=n%3A1389396031&ref=nb_sb_noss\"\n",
    "\n",
    "# Headers to mimic a browser request\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c87317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send HTTP request\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e7a7345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to hold the extracted data\n",
    "product_names = []\n",
    "ratings = []\n",
    "base_prices = []\n",
    "mrps = []\n",
    "service_types = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59412c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data\n",
    "for item in soup.find_all('div', class_='s-main-slot s-result-list s-search-results sg-row'):\n",
    "    for product in item.find_all('div', class_='s-result-item'):\n",
    "        # Product Name\n",
    "        name_tag = product.find('span', class_='a-text-normal')\n",
    "        product_name = name_tag.text.strip() if name_tag else 'N/A'\n",
    "        \n",
    "        # Rating\n",
    "        rating_tag = product.find('span', class_='a-icon-alt')\n",
    "        rating = rating_tag.text.strip() if rating_tag else 'N/A'\n",
    "        \n",
    "        # Base Price\n",
    "        base_price_tag = product.find('span', class_='a-price-whole')\n",
    "        base_price = base_price_tag.text.strip() if base_price_tag else 'N/A'\n",
    "        \n",
    "        # MRP\n",
    "        mrp_tag = product.find('span', class_='a-price a-text-price')\n",
    "        mrp = mrp_tag.text.strip() if mrp_tag else 'N/A'\n",
    "        \n",
    "        # Service Type\n",
    "        service_type = 'N/A'  # Amazon doesn't typically list a specific \"Service Type\" on this page\n",
    "        \n",
    "        product_names.append(product_name)\n",
    "        ratings.append(rating)\n",
    "        base_prices.append(base_price)\n",
    "        mrps.append(mrp)\n",
    "        service_types.append(service_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f13dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Product_name': product_names,\n",
    "    'Rating': ratings,\n",
    "    'Base_Price': base_prices,\n",
    "    'MRP': mrps,\n",
    "    'Service_type': service_types\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6857e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV\n",
    "df.to_csv('amazon_tv_data.csv', index=False)\n",
    "\n",
    "# print(\"Data saved to amazon_tv_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3c3100",
   "metadata": {},
   "source": [
    "## Extract Data from multiple Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9124836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def extract_data_from_page(soup):\n",
    "    product_names = []\n",
    "    ratings = []\n",
    "    base_prices = []\n",
    "    mrps = []\n",
    "    service_types = []\n",
    "\n",
    "    for item in soup.find_all('div', class_='s-main-slot s-result-list s-search-results sg-row'):\n",
    "        for product in item.find_all('div', class_='s-result-item'):\n",
    "            # Product Name\n",
    "            name_tag = product.find('span', class_='a-text-normal')\n",
    "            product_name = name_tag.text.strip() if name_tag else 'N/A'\n",
    "            \n",
    "            # Rating\n",
    "            rating_tag = product.find('span', class_='a-icon-alt')\n",
    "            rating = rating_tag.text.strip() if rating_tag else 'N/A'\n",
    "            \n",
    "            # Base Price\n",
    "            base_price_tag = product.find('span', class_='a-price-whole')\n",
    "            base_price = base_price_tag.text.strip() if base_price_tag else 'N/A'\n",
    "            \n",
    "            # MRP\n",
    "            mrp_tag = product.find('span', class_='a-price a-text-price')\n",
    "            mrp = mrp_tag.text.strip() if mrp_tag else 'N/A'\n",
    "            \n",
    "            # Service Type\n",
    "            service_type = 'N/A'  # Amazon doesn't typically list a specific \"Service Type\" on this page\n",
    "            \n",
    "            product_names.append(product_name)\n",
    "            ratings.append(rating)\n",
    "            base_prices.append(base_price)\n",
    "            mrps.append(mrp)\n",
    "            service_types.append(service_type)\n",
    "    \n",
    "    return product_names, ratings, base_prices, mrps, service_types\n",
    "\n",
    "def main():\n",
    "    base_url = \"https://www.amazon.in/s?k=TV&rh=n%3A1389396031&page=\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    all_product_names = []\n",
    "    all_ratings = []\n",
    "    all_base_prices = []\n",
    "    all_mrps = []\n",
    "    all_service_types = []\n",
    "    \n",
    "    for page in range(1, 11):  # Scraping pages 1 to 10\n",
    "        print(f\"Scraping page {page}...\")\n",
    "        response = requests.get(base_url + str(page), headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        product_names, ratings, base_prices, mrps, service_types = extract_data_from_page(soup)\n",
    "        \n",
    "        all_product_names.extend(product_names)\n",
    "        all_ratings.extend(ratings)\n",
    "        all_base_prices.extend(base_prices)\n",
    "        all_mrps.extend(mrps)\n",
    "        all_service_types.extend(service_types)\n",
    "        \n",
    "        # To avoid being blocked by Amazon, introduce a delay between requests\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Product_name': all_product_names,\n",
    "        'Rating': all_ratings,\n",
    "        'Base_Price': all_base_prices,\n",
    "        'MRP': all_mrps,\n",
    "        'Service_type': all_service_types\n",
    "    })\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75bc8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV\n",
    "df.to_csv('amazon_tv_data_multiple_pages.csv', index=False)\n",
    "# print(\"Data saved to amazon_tv_data_multiple_pages.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6109ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
